{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer, confusion_matrix\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13664fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to the dataset used for this thesis\n",
    "# https://www.kaggle.com/datasets/dkapitan/dutch-restaurant-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset and transfer it to a dataframe\n",
    "file_path = filepath # add the path to the file here\n",
    "df_raw_data = pd.read_parquet(file_path) # Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information of the raw dataset\n",
    "print(df_raw_data.head(5)) # Print the first five rows of the data\n",
    "print(len(df_raw_data)) # Print the number of rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary preprocessing steps for thesis\n",
    "df_pp_data = df_raw_data.copy()\n",
    "\n",
    "# Remove the unknown character in the avgPrice column\n",
    "df_pp_data[\"avgPrice\"] = df_pp_data[\"avgPrice\"].str.replace(\"â\\u0082¬\",\"\")\n",
    "df_pp_data[\"avgPrice\"] = df_pp_data[\"avgPrice\"].str.replace(\"\\u0080\",\"\")\n",
    "\n",
    "# Convert the columns containing numeric information to numeric\n",
    "columns_to_convert = [\"scoreTotal\", \"avgPrice\", \"reviewerNumReviews\", \"reviewScoreOverall\", \"reviewScoreFood\", \"reviewScoreService\", \"reviewScoreAmbiance\"]\n",
    "df_pp_data[columns_to_convert] = df_pp_data[columns_to_convert].apply(pd.to_numeric, errors = \"coerce\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f680a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful information per variable\n",
    "\n",
    "unique_restaurants = df_pp_data[\"restoName\"].nunique() # number of unique restaurants\n",
    "unique_reviewers = df_pp_data[\"reviewerId\"].nunique() # number of unique reviewers\n",
    "\n",
    "# information about numeric values to check if they contain impossible or implausible values\n",
    "\n",
    "for column in df_pp_data.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df_pp_data[column]):\n",
    "        avg = df_pp_data[column].mean()\n",
    "        min_val = df_pp_data[column].min()\n",
    "        max_val = df_pp_data[column].max()\n",
    "        print(f\"Variable: {column}, Average: {avg}, Minimum: {min_val}, Maximum: {max_val}\")\n",
    "\n",
    "print(\"Total number of restaurants:\", unique_restaurants)\n",
    "print(\"Total number of reviewers:\", unique_reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all reviews with a score of 5 and 6 to exclude neutral sentiments from the data\n",
    "df_pp_data = df_pp_data[~((df_pp_data[\"reviewScoreFood\"] == 5) | (df_pp_data[\"reviewScoreFood\"] == 6) |\n",
    "                         (df_pp_data[\"reviewScoreService\"] == 5) | (df_pp_data[\"reviewScoreService\"] == 6) |\n",
    "                           (df_pp_data[\"reviewScoreAmbiance\"] == 5) | (df_pp_data[\"reviewScoreAmbiance\"] == 6))]\n",
    "print(len(df_pp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36432117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average price of restaurants\n",
    "average_prices = df_pp_data[\"avgPrice\"].dropna() \n",
    "\n",
    "# Plot a histogram containing the distribution of the prica variable\n",
    "plt.figure(figsize=(10, 6))  \n",
    "plt.hist(average_prices, bins=30, color='blue', alpha=0.7)\n",
    "plt.xlabel('Average Price', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the personal review scores to sentiments\n",
    "\n",
    "columns_to_change = [\"reviewScoreFood\", \"reviewScoreService\", \"reviewScoreAmbiance\"]\n",
    "bins = [1,6,10] # split the reviews into positive and negative sentiments\n",
    "labels = [\"Negative\", \"Positive\"]\n",
    "for column in columns_to_change:\n",
    "    df_pp_data[column] = pd.cut(df_pp_data[column], bins = bins, labels = labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the city name from the address\n",
    "# Function to extract the second to last element from the address\n",
    "def extract_second_to_last_element(address):\n",
    "    address_components = address.split()\n",
    "    if len(address_components) >= 2:\n",
    "        return address_components[-2]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# create a new feature that contains only the name of the city\n",
    "df_pp_data[\"City\"] = df_pp_data[\"address\"].apply(extract_second_to_last_element)\n",
    "\n",
    "unique_values_city = df_pp_data[\"City\"].value_counts()\n",
    "print(unique_values_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that contain missing values for the important variables\n",
    "# important variables: restoId, avgPrice, reviewScoreOverall, reviewScoreFood, reviewScoreService, reviewScoreAmbiance, reviewText, City\n",
    "df_nomissing = df_pp_data.copy()\n",
    "\n",
    "important_features = [\"restoId\", \"avgPrice\", \"reviewScoreOverall\", \"reviewScoreFood\", \"reviewScoreService\", \"reviewScoreAmbiance\", \"reviewText\", \"City\"]\n",
    "\n",
    "df_nomissing = df_nomissing.dropna(subset = important_features)\n",
    "\n",
    "print(len(df_pp_data))\n",
    "print(len(df_nomissing)) # print the new length of the dataframe to check how many rows remain in the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new variable that contains the length of a review\n",
    "df_nomissing[\"reviewLength\"] = df_nomissing[\"reviewText\"].apply(len)\n",
    "\n",
    "descriptives_length = df_nomissing[\"reviewLength\"].describe()\n",
    "print(descriptives_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the review length variable before removing reviews based on their length\n",
    "plt.hist(df_nomissing[\"reviewLength\"], bins = 100, color = \"grey\", edgecolor = \"black\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35954b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove reviews that are too long and too short\n",
    "# Reviews with less than 20 characters and more than 2000 characters will be removed\n",
    "df_lessreviews = df_nomissing.copy()\n",
    "df_lessreviews = df_lessreviews[(df_lessreviews[\"reviewLength\"] >= 20) & (df_lessreviews[\"reviewLength\"] <= 2000)]\n",
    "\n",
    "print(len(df_lessreviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the review length variable after removing long and short reviews\n",
    "plt.hist(df_lessreviews[\"reviewLength\"], bins = 100, color = \"grey\", edgecolor = \"black\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eadbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how many positive and negative reviews exist in the dataset for each label\n",
    "counts_food = df_lessreviews[\"reviewScoreFood\"].value_counts()\n",
    "counts_service = df_lessreviews[\"reviewScoreService\"].value_counts()\n",
    "counts_ambiance = df_lessreviews[\"reviewScoreAmbiance\"].value_counts()\n",
    "\n",
    "print(counts_food)\n",
    "print(counts_service)\n",
    "print(counts_ambiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda06e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distributions of sentiments per aspect\n",
    "\n",
    "counts_sentiments = pd.DataFrame({\n",
    "    \"Food\": counts_food,\n",
    "    \"Service\": counts_service,\n",
    "    \"Ambiance\": counts_ambiance\n",
    "}).fillna(0)\n",
    "\n",
    "counts_sentiments = counts_sentiments.T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "positions = range(len(counts_sentiments))\n",
    "\n",
    "positive_bars = plt.bar(positions, counts_sentiments[\"Positive\"], bar_width, label = \"Positive\", color = \"lightblue\")\n",
    "negative_bars = plt.bar([p + bar_width for p in positions], counts_sentiments[\"Negative\"], bar_width, label = \"Negative\", color = \"lightcoral\")\n",
    "\n",
    "\n",
    "ax.set_xticks([p + bar_width / 2 for p in positions])\n",
    "ax.set_xticklabels(counts_sentiments.index, fontsize=12)\n",
    "plt.xlabel('Aspects', fontsize=14)\n",
    "plt.ylabel('Number of instances', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly remove rows with all positive labels to make the dataset more balanced (is still imbalanced after for some aspects, but less imbalanced),\n",
    "# also remove rows because the amount of data is computationally expensive\n",
    "\n",
    "sentiment_columns = [\"reviewScoreFood\", \"reviewScoreService\", \"reviewScoreAmbiance\"]\n",
    "df_sentiment = df_lessreviews[sentiment_columns]\n",
    "\n",
    "positive_rows = np.all(df_sentiment == \"Positive\", axis = 1)\n",
    "\n",
    "sampled_positive_rows = df_lessreviews[positive_rows].sample(n = 232830, random_state = 68)\n",
    "\n",
    "df_lessreviews = df_lessreviews.drop(sampled_positive_rows.index)\n",
    "\n",
    "print(len(df_lessreviews))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732570a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze how many positive and negative reviews are left in the reduced dataframe\n",
    "counts_food = df_lessreviews[\"reviewScoreFood\"].value_counts()\n",
    "counts_service = df_lessreviews[\"reviewScoreService\"].value_counts()\n",
    "counts_ambiance = df_lessreviews[\"reviewScoreAmbiance\"].value_counts()\n",
    "\n",
    "print(counts_food)\n",
    "print(counts_service)\n",
    "print(counts_ambiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distributions of sentiments per aspect\n",
    "\n",
    "counts_sentiments = pd.DataFrame({\n",
    "    \"Food\": counts_food,\n",
    "    \"Service\": counts_service,\n",
    "    \"Ambiance\": counts_ambiance\n",
    "}).fillna(0)\n",
    "\n",
    "counts_sentiments = counts_sentiments.T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "positions = range(len(counts_sentiments))\n",
    "\n",
    "positive_bars = plt.bar(positions, counts_sentiments[\"Positive\"], bar_width, label = \"Positive\", color = \"lightblue\")\n",
    "negative_bars = plt.bar([p + bar_width for p in positions], counts_sentiments[\"Negative\"], bar_width, label = \"Negative\", color = \"lightcoral\")\n",
    "\n",
    "ax.set_xticks([p + bar_width / 2 for p in positions])\n",
    "ax.set_xticklabels(counts_sentiments.index, fontsize=12)\n",
    "plt.xlabel('Aspects', fontsize=14)\n",
    "plt.ylabel('Number of instances', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentiments into labels (negative = 0, positive = 1)\n",
    "\n",
    "class_mapping = {\"Negative\": 0, \"Positive\": 1}\n",
    "\n",
    "# Initialize LabelEncoder with the custom mapping\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = class_mapping.keys()\n",
    "label_encoder.transform = lambda x: [class_mapping[label] for label in x]\n",
    "\n",
    "# Fit and transform the target variables using the custom mapping\n",
    "df_lessreviews[\"labelFood\"] = label_encoder.transform(df_lessreviews[\"reviewScoreFood\"])\n",
    "df_lessreviews[\"labelService\"] = label_encoder.transform(df_lessreviews[\"reviewScoreService\"])\n",
    "df_lessreviews[\"labelAmbiance\"] = label_encoder.transform(df_lessreviews[\"reviewScoreAmbiance\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the price variable\n",
    "scaler = MinMaxScaler()\n",
    "df_lessreviews[\"avgPrice\"] = scaler.fit_transform(df_lessreviews[[\"avgPrice\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing reviews for SVM and Random Forests\n",
    "df_preprocessing = df_lessreviews.copy()\n",
    "\n",
    "# make a copy of the reviewText variable for preprocessing steps for SVM and Random Forests\n",
    "df_preprocessing[\"reviewTextSVMRF\"] = df_preprocessing[\"reviewText\"].copy()\n",
    "\n",
    "# make reviews lower cased\n",
    "df_preprocessing[\"reviewTextSVMRF\"] = df_preprocessing[\"reviewTextSVMRF\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e227783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "df_preprocessing[\"reviewTextSVMRF\"] = df_preprocessing[\"reviewTextSVMRF\"].str.replace(r'[^\\w\\s]', '', regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946748af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "\n",
    "# Download the 'punkt' resource\n",
    "nltk.download('punkt')\n",
    "\n",
    "df_preprocessing[\"tokenizedTextSVMRF\"] = df_preprocessing[\"reviewTextSVMRF\"].apply(lambda x: word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02194c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words\n",
    "\n",
    "stop_words = set(stopwords.words(\"dutch\"))\n",
    "\n",
    "# Define a function to remove Dutch stopwords from the reviews\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply stop word removal to the 'text_column'\n",
    "df_preprocessing['tokenizedTextSVMRF'] = df_preprocessing['tokenizedTextSVMRF'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7aa07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "df_preprocessing[\"stemmedReviewSVMRF\"] = df_preprocessing[\"tokenizedTextSVMRF\"].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff26fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply word embeddings\n",
    "df_embeddings = df_preprocessing.copy()\n",
    "\n",
    "word2vec_model = Word2Vec(sentences = df_embeddings[\"stemmedReviewSVMRF\"], vector_size = 100, window = 5, min_count = 5, workers = 4)\n",
    "\n",
    "# Vocabulary size\n",
    "wordlist = list(word2vec_model.wv.index_to_key)\n",
    "\n",
    "# Embedding matrix\n",
    "embedding_matrix = [word2vec_model.wv[word] for word in wordlist]\n",
    "\n",
    "# Convert the embedding matrix into a dataframe\n",
    "word2vec_embeddings = pd.DataFrame(embedding_matrix, index=wordlist)\n",
    "\n",
    "print(word2vec_embeddings) # Print the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to average word embeddings\n",
    "def average_word_vectors(wordlist, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype = \"float64\")\n",
    "    n_words = 0.\n",
    "    \n",
    "    for word in wordlist:\n",
    "        if word in vocabulary:\n",
    "            n_words += 1.\n",
    "            feature_vector += word_vectors[word]\n",
    "            \n",
    "    if n_words:\n",
    "        feature_vector /= n_words\n",
    "        \n",
    "    return feature_vector\n",
    "\n",
    "word_vectors = word2vec_model.wv\n",
    "\n",
    "# Compute the average word embeddings for each review\n",
    "vocabulary = set(word_vectors.index_to_key)\n",
    "df_embeddings[\"word_vectors\"] = [average_word_vectors(wordlist, word_vectors, vocabulary, 100) for wordlist in df_embeddings[\"stemmedReviewSVMRF\"]]\n",
    "\n",
    "# Convert to array\n",
    "df_embeddings[\"array\"] = np.array(df_embeddings[\"word_vectors\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eca622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many restaurants are in the final dataframe\n",
    "unique_restaurants2 = df_embeddings[\"restoName\"].nunique() # number of restaurants\n",
    "print(unique_restaurants2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the City variable with target encoder for SVM and RF\n",
    "\n",
    "# Initialize the Target Encoder \n",
    "encoder_city = ce.TargetEncoder()\n",
    "\n",
    "# Fit the encoder on the City column and the target variables and make a new column in the dataframe\n",
    "df_embeddings[\"CityDummyFood\"] = encoder_city.fit_transform(df_embeddings[\"City\"], df_embeddings[\"labelFood\"])\n",
    "df_embeddings[\"CityDummyService\"] = encoder_city.fit_transform(df_embeddings[\"City\"], df_embeddings[\"labelService\"])\n",
    "df_embeddings[\"CityDummyAmbiance\"] = encoder_city.fit_transform(df_embeddings[\"City\"], df_embeddings[\"labelAmbiance\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a train, validation, and test set\n",
    "\n",
    "# First split the data into train and temp sets\n",
    "df_train, df_temp = train_test_split(df_embeddings, test_size= 0.2, random_state=68)\n",
    "\n",
    "# Then split the temp set into validation and test sets\n",
    "df_validation, df_test = train_test_split(df_temp, test_size= 0.5, random_state=68)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print(\"Training set samples:\", len(df_train))\n",
    "print(\"Validation set samples:\", len(df_validation))\n",
    "print(\"Test set samples:\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf35bda",
   "metadata": {},
   "source": [
    "# Make train, validation and test sets per aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datsets with x and y variables\n",
    "\n",
    "# For the Food aspect\n",
    "x_train_food = np.vstack(df_train[\"array\"].values)\n",
    "y_train_food = df_train[\"labelFood\"]\n",
    "\n",
    "x_validation_food = np.vstack(df_validation[\"array\"].values)\n",
    "y_validation_food = df_validation[\"labelFood\"]\n",
    "\n",
    "x_test_food = np.vstack(df_test[\"array\"].values)\n",
    "y_test_food = df_test[\"labelFood\"]\n",
    "\n",
    "# For the service aspect\n",
    "x_train_service = np.vstack(df_train[\"array\"].values)\n",
    "y_train_service = df_train[\"labelService\"]\n",
    "\n",
    "x_validation_service = np.vstack(df_validation[\"array\"].values)\n",
    "y_validation_service = df_validation[\"labelService\"]\n",
    "\n",
    "x_test_service = np.vstack(df_test[\"array\"].values)\n",
    "y_test_service = df_test[\"labelService\"]\n",
    "\n",
    "# For the ambiance aspect\n",
    "x_train_ambiance = np.vstack(df_train[\"array\"].values)\n",
    "y_train_ambiance = df_train[\"labelAmbiance\"]\n",
    "\n",
    "x_validation_ambiance = np.vstack(df_validation[\"array\"].values)\n",
    "y_validation_ambiance = df_validation[\"labelAmbiance\"]\n",
    "\n",
    "x_test_ambiance = np.vstack(df_test[\"array\"].values)\n",
    "y_test_ambiance = df_test[\"labelAmbiance\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new x sets that also contain information about price and location of the restaurants\n",
    "\n",
    "# For the Food aspect\n",
    "x_train_food_exp = np.hstack((np.vstack(df_train[\"array\"].values), df_train[[\"avgPrice\", \"CityDummyFood\"]].values))\n",
    "y_train_food_exp = df_train[\"labelFood\"]\n",
    "\n",
    "x_validation_food_exp = np.hstack((np.vstack(df_validation[\"array\"].values), df_validation[[\"avgPrice\", \"CityDummyFood\"]].values))\n",
    "y_validation_food_exp = df_validation[\"labelFood\"]\n",
    "\n",
    "x_test_food_exp = np.hstack((np.vstack(df_test[\"array\"].values), df_test[[\"avgPrice\", \"CityDummyFood\"]].values))\n",
    "y_test_food_exp = df_test[\"labelFood\"]\n",
    "\n",
    "# For the Service aspect\n",
    "x_train_service_exp = np.hstack((np.vstack(df_train[\"array\"].values), df_train[[\"avgPrice\", \"CityDummyService\"]].values))\n",
    "y_train_service_exp = df_train[\"labelService\"]\n",
    "\n",
    "x_validation_service_exp = np.hstack((np.vstack(df_validation[\"array\"].values), df_validation[[\"avgPrice\", \"CityDummyService\"]].values))\n",
    "y_validation_service_exp = df_validation[\"labelService\"]\n",
    "\n",
    "x_test_service_exp = np.hstack((np.vstack(df_test[\"array\"].values), df_test[[\"avgPrice\", \"CityDummyService\"]].values))\n",
    "y_test_service_exp = df_test[\"labelService\"]\n",
    "\n",
    "# For the ambiance aspect\n",
    "x_train_ambiance_exp = np.hstack((np.vstack(df_train[\"array\"].values), df_train[[\"avgPrice\", \"CityDummyAmbiance\"]].values))\n",
    "y_train_ambiance_exp = df_train[\"labelAmbiance\"]\n",
    "\n",
    "x_validation_ambiance_exp = np.hstack((np.vstack(df_validation[\"array\"].values), df_validation[[\"avgPrice\", \"CityDummyAmbiance\"]].values))\n",
    "y_validation_ambiance_exp = df_validation[\"labelAmbiance\"]\n",
    "\n",
    "x_test_ambiance_exp = np.hstack((np.vstack(df_test[\"array\"].values), df_test[[\"avgPrice\", \"CityDummyAmbiance\"]].values))\n",
    "y_test_ambiance_exp = df_test[\"labelAmbiance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly make train sets smaller for sets with experience included to make runtime hyperparameter tuning reasonable\n",
    "\n",
    "# For the food aspect\n",
    "random_indices_food = np.random.choice(len(x_train_food_exp), size = 8000, replace = False)\n",
    "x_train_food_exp_small = x_train_food_exp[random_indices_food]\n",
    "y_train_food_exp_small = df_train[\"labelFood\"].iloc[random_indices_food]\n",
    "\n",
    "# For the service aspect\n",
    "random_indices_service = np.random.choice(len(x_train_service_exp), size = 8000, replace = False)\n",
    "x_train_service_exp_small = x_train_service_exp[random_indices_service]\n",
    "y_train_service_exp_small = df_train[\"labelService\"].iloc[random_indices_service]\n",
    "\n",
    "# For the ambiance aspect\n",
    "random_indices_ambiance = np.random.choice(len(x_train_ambiance_exp), size = 8000, replace = False)\n",
    "x_train_ambiance_exp_small = x_train_ambiance_exp[random_indices_ambiance]\n",
    "y_train_ambiance_exp_small = df_train[\"labelAmbiance\"].iloc[random_indices_ambiance]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78fb14",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search to define parameters for SVM\n",
    "\n",
    "# The parameter grid for the random search\n",
    "param_dist_SVM = {\n",
    "    \"C\": uniform(loc = 0.1, scale = 100-0.1),\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "    \"class_weight\": [None, \"balanced\", {0: 2, 1: 1}],\n",
    "    \"gamma\": uniform(loc = 0.001, scale = 1 - 0.001),\n",
    "    \"degree\": [2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "# Define the scorer for F1-score\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# A list of the features and the targets\n",
    "feature_target_pairs_SVM = [\n",
    "    {\"X\": x_train_food, \"y\": y_train_food, \"X-test\": x_validation_food, \"y-test\": y_validation_food},\n",
    "    {\"X\": x_train_service, \"y\": y_train_service, \"X-test\": x_validation_service, \"y-test\": y_validation_service},\n",
    "    {\"X\": x_train_ambiance, \"y\": y_train_ambiance, \"X-test\": x_validation_ambiance, \"y-test\": y_validation_ambiance},\n",
    "    {\"X\": x_train_food_exp_small, \"y\": y_train_food_exp_small, \"X-test\": x_validation_food_exp, \"y-test\": y_validation_food_exp},\n",
    "    {\"X\": x_train_service_exp_small, \"y\": y_train_service_exp_small, \"X-test\": x_validation_service_exp, \"y-test\": y_validation_service_exp},\n",
    "    {\"X\": x_train_ambiance_exp_small, \"y\": y_train_ambiance_exp_small, \"X-test\": x_validation_ambiance_exp, \"y-test\": y_validation_ambiance_exp}\n",
    "]\n",
    "\n",
    "# Perform random search for each pair\n",
    "for pair in feature_target_pairs_SVM:\n",
    "    svm = SVC()\n",
    "    random_search = RandomizedSearchCV(svm, param_dist_SVM, n_iter=10, cv=5, scoring = scorer, refit = True, random_state = 68)\n",
    "    random_search.fit(pair[\"X\"], pair[\"y\"])\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best cross-validation score:\", random_search.best_score_)\n",
    "    print()\n",
    "\n",
    "    best_svm = random_search.best_estimator_\n",
    "    test_score = best_svm.score(pair[\"X-test\"], pair[\"y-test\"])\n",
    "    print(\"Validation set score:\", test_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f66137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random search to define parameters for Random forests\n",
    "\n",
    "# The parameter grid for the randomized search\n",
    "param_dist_RF = {\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"n_estimators\": randint(10,800),\n",
    "    \"max_depth\": [None] + list(range(5, 31, 5)),\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\": randint(1, 20)\n",
    "}\n",
    "\n",
    "# Define the scorer for F1-score\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# A list of the features and the targets\n",
    "feature_target_pairs_RF = [\n",
    "    {\"X\": x_train_food, \"y\": y_train_food, \"X-test\": x_validation_food, \"y-test\": y_validation_food},\n",
    "    {\"X\": x_train_service, \"y\": y_train_service, \"X-test\": x_validation_service, \"y-test\": y_validation_service},\n",
    "    {\"X\": x_train_ambiance, \"y\": y_train_ambiance, \"X-test\": x_validation_ambiance, \"y-test\": y_validation_ambiance},\n",
    "    {\"X\": x_train_food_exp_small, \"y\": y_train_food_exp_small, \"X-test\": x_validation_food_exp, \"y-test\": y_validation_food_exp},\n",
    "    {\"X\": x_train_service_exp_small, \"y\": y_train_service_exp_small, \"X-test\": x_validation_service_exp, \"y-test\": y_validation_service_exp},\n",
    "    {\"X\": x_train_ambiance_exp_small, \"y\": y_train_ambiance_exp_small, \"X-test\": x_validation_ambiance_exp, \"y-test\": y_validation_ambiance_exp}\n",
    "]\n",
    "\n",
    "# Perform randomized search for each pair\n",
    "for pair in feature_target_pairs_RF:\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    random_search = RandomizedSearchCV(rf_classifier, param_dist_RF, n_iter = 10, cv=5, scoring = scorer, refit = True, random_state = 68)\n",
    "    random_search.fit(pair[\"X\"], pair[\"y\"])\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best cross-validation score:\", random_search.best_score_)\n",
    "    print()\n",
    "\n",
    "    best_rf = random_search.best_estimator_\n",
    "    test_score = best_rf.score(pair[\"X-test\"], pair[\"y-test\"])\n",
    "    print(\"Validation set score:\", test_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ac8c6",
   "metadata": {},
   "source": [
    "# Run optimal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the train and validation sets for each aspect\n",
    "\n",
    "# food aspect\n",
    "x_train_combined_food = np.vstack([x_train_food, x_validation_food])\n",
    "y_train_combined_food = pd.concat([y_train_food, y_validation_food])\n",
    "\n",
    "x_train_combined_food_exp = np.vstack([x_train_food_exp, x_validation_food_exp])\n",
    "y_train_combined_food_exp = pd.concat([y_train_food_exp, y_validation_food_exp])\n",
    "\n",
    "# service aspect\n",
    "x_train_combined_service = np.vstack([x_train_service, x_validation_service])\n",
    "y_train_combined_service = pd.concat([y_train_service, y_validation_service])\n",
    "\n",
    "x_train_combined_service_exp = np.vstack([x_train_service_exp, x_validation_service_exp])\n",
    "y_train_combined_service_exp = pd.concat([y_train_service_exp, y_validation_service_exp])\n",
    "\n",
    "# ambiance aspect\n",
    "x_train_combined_ambiance = np.vstack([x_train_ambiance, x_validation_ambiance])\n",
    "y_train_combined_ambiance = pd.concat([y_train_ambiance, y_validation_ambiance])\n",
    "\n",
    "x_train_combined_ambiance_exp = np.vstack([x_train_ambiance_exp, x_validation_ambiance_exp])\n",
    "y_train_combined_ambiance_exp = pd.concat([y_train_ambiance_exp, y_validation_ambiance_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fe38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM only review food\n",
    "\n",
    "# initiate model\n",
    "svm_food = SVC(C = 26.011, class_weight = None, degree = 4, gamma = 0.148, kernel = \"linear\")\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "svm_food.fit(x_train_combined_food, y_train_combined_food)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_food_pred = svm_food.predict(x_test_food)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_svm_food = classification_report(y_test_food, svm_food_pred)\n",
    "\n",
    "print(\"Classification report SVM food: \\n\", class_rep_svm_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_svm_food = confusion_matrix(y_test_food, svm_food_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_food, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - SVM Food')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM only review service\n",
    "\n",
    "# initiate model\n",
    "svm_service = SVC(C = 26.011, class_weight = None, degree = 4, gamma = 0.148, kernel = \"linear\")\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "svm_service.fit(x_train_combined_service, y_train_combined_service)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_service_pred = svm_service.predict(x_test_service)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_svm_service = classification_report(y_test_service, svm_service_pred)\n",
    "\n",
    "print(\"Classification report SVM service: \\n\", class_rep_svm_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddfd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_svm_service = confusion_matrix(y_test_service, svm_service_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_service, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - SVM Service')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a685214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM only review ambiance\n",
    "\n",
    "# initiate model\n",
    "svm_ambiance = SVC(C = 54.3249, class_weight = None, degree = 5, gamma = 0.93846, kernel = \"rbf\")\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "svm_ambiance.fit(x_train_combined_ambiance, y_train_combined_ambiance)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_ambiance_pred = svm_ambiance.predict(x_test_ambiance)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_svm_ambiance = classification_report(y_test_ambiance, svm_ambiance_pred)\n",
    "\n",
    "print(\"Classification report SVM ambiance: \\n\", class_rep_svm_ambiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e454514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_svm_ambiance = confusion_matrix(y_test_ambiance, svm_ambiance_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_ambiance, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - SVM Ambiance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ea55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM food with expectations\n",
    "\n",
    "# initiate model\n",
    "svm_food_exp = SVC(C = 26.011, class_weight = None, degree = 4, gamma = 0.148, kernel = \"linear\")\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "svm_food_exp.fit(x_train_combined_food_exp, y_train_combined_food_exp)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_food_exp_pred = svm_food_exp.predict(x_test_food_exp)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_svm_food_exp = classification_report(y_test_food_exp, svm_food_exp_pred)\n",
    "\n",
    "print(\"Classification report SVM food with expectations: \\n\", class_rep_svm_food_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b45761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_svm_food_exp = confusion_matrix(y_test_food_exp, svm_food_exp_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_food_exp, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - SVM Food Expectations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3227db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM service with expectations\n",
    "\n",
    "# initiate model\n",
    "svm_service_exp = SVC(C = 26.011, class_weight = None, degree = 4, gamma = 0.148, kernel = \"linear\")\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "svm_service_exp.fit(x_train_combined_service_exp, y_train_combined_service_exp)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_service_exp_pred = svm_service_exp.predict(x_test_service_exp)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_svm_service_exp = classification_report(y_test_service_exp, svm_service_exp_pred)\n",
    "\n",
    "print(\"Classification report SVM service with expectations: \\n\", class_rep_svm_service_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319390ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_svm_service_exp = confusion_matrix(y_test_service_exp, svm_service_exp_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_service_exp, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - SVM Service Expectations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM ambiance with expectations\n",
    "\n",
    "# initiate model\n",
    "svm_ambiance_exp = SVC(C = 29.0139, class_weight = {0: 2, 1: 1}, degree = 6, gamma = 0.655, kernel = \"linear\")\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "svm_ambiance_exp.fit(x_train_combined_ambiance_exp, y_train_combined_ambiance_exp)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_ambiance_exp_pred = svm_ambiance_exp.predict(x_test_ambiance_exp)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_svm_ambiance_exp = classification_report(y_test_ambiance_exp, svm_ambiance_exp_pred)\n",
    "\n",
    "print(\"Classification report SVM ambiance with expectations: \\n\", class_rep_svm_ambiance_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_svm_ambiance_exp = confusion_matrix(y_test_ambiance_exp, svm_ambiance_exp_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_ambiance_exp, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - SVM Ambiance Expectations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eee596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF only review food\n",
    "\n",
    "# initiate model\n",
    "rf_food = RandomForestClassifier(bootstrap = False, max_depth = 25, min_samples_leaf = 8, min_samples_split = 16, n_estimators = 548)\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "rf_food.fit(x_train_combined_food, y_train_combined_food)\n",
    "\n",
    "# make predictions on the test set\n",
    "rf_food_pred = rf_food.predict(x_test_food)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_rf_food = classification_report(y_test_food, rf_food_pred)\n",
    "\n",
    "print(\"Classification report Random Forests food: \\n\", class_rep_rf_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f219626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_rf_food = confusion_matrix(y_test_food, rf_food_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_food, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Random Forests Food')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF only review service\n",
    "\n",
    "# initiate model\n",
    "rf_service = RandomForestClassifier(bootstrap = False, max_depth = 25, min_samples_leaf = 8, min_samples_split = 16, n_estimators = 548)\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "rf_service.fit(x_train_combined_service, y_train_combined_service)\n",
    "\n",
    "# make predictions on the test set\n",
    "rf_service_pred = rf_service.predict(x_test_service)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_rf_service = classification_report(y_test_service, rf_service_pred)\n",
    "\n",
    "print(\"Classification report Random Forests service: \\n\", class_rep_rf_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_rf_service = confusion_matrix(y_test_service, rf_service_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_service, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Random Forests Service')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF only review ambiance\n",
    "\n",
    "# initiate model\n",
    "rf_ambiance = RandomForestClassifier(bootstrap = False, max_depth = 25, min_samples_leaf = 8, min_samples_split = 16, n_estimators = 548)\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "rf_ambiance.fit(x_train_combined_ambiance, y_train_combined_ambiance)\n",
    "\n",
    "# make predictions on the test set\n",
    "rf_ambiance_pred = rf_ambiance.predict(x_test_ambiance)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_rf_ambiance = classification_report(y_test_ambiance, rf_ambiance_pred)\n",
    "\n",
    "print(\"Classification report Random Forests ambiance: \\n\", class_rep_rf_ambiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_rf_ambiance = confusion_matrix(y_test_ambiance, rf_ambiance_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_ambiance, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Random Forests Ambiance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF food with expectations\n",
    "\n",
    "# initiate model\n",
    "rf_food_exp = RandomForestClassifier(bootstrap = False, max_depth = 15, min_samples_leaf = 9, min_samples_split = 13, n_estimators = 453)\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "rf_food_exp.fit(x_train_combined_food_exp, y_train_combined_food_exp)\n",
    "\n",
    "# make predictions on the test set\n",
    "rf_food_exp_pred = rf_food_exp.predict(x_test_food_exp)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_rf_food_exp = classification_report(y_test_food_exp, rf_food_exp_pred)\n",
    "\n",
    "print(\"Classification report Random Forests food with expectations: \\n\", class_rep_rf_food_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_rf_food_exp = confusion_matrix(y_test_food_exp, rf_food_exp_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_food_exp, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Random Forests Food Expectations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF service with expectations\n",
    "\n",
    "# initiate model\n",
    "rf_service_exp = RandomForestClassifier(bootstrap = False, max_depth = 25, min_samples_leaf = 8, min_samples_split = 16, n_estimators = 548)\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "rf_service_exp.fit(x_train_combined_service_exp, y_train_combined_service_exp)\n",
    "\n",
    "# make predictions on the test set\n",
    "rf_service_exp_pred = rf_service_exp.predict(x_test_service_exp)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_rf_service_exp = classification_report(y_test_service_exp, rf_service_exp_pred)\n",
    "\n",
    "print(\"Classification report Random Forests service with expectations: \\n\", class_rep_rf_service_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84486c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_rf_service_exp = confusion_matrix(y_test_service_exp, rf_service_exp_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_service_exp, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Random Forests Service Expectations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF ambiance with expectations\n",
    "\n",
    "# initiate model\n",
    "rf_ambiance_exp = RandomForestClassifier(bootstrap = False, max_depth = 25, min_samples_leaf = 8, min_samples_split = 16, n_estimators = 548)\n",
    "\n",
    "# Train the model on the combined train and validation sets\n",
    "rf_ambiance_exp.fit(x_train_combined_ambiance_exp, y_train_combined_ambiance_exp)\n",
    "\n",
    "# make predictions on the test set\n",
    "rf_ambiance_exp_pred = rf_ambiance_exp.predict(x_test_ambiance_exp)\n",
    "\n",
    "# evaluate performance of the model on the test set\n",
    "class_rep_rf_ambiance_exp = classification_report(y_test_ambiance_exp, rf_ambiance_exp_pred)\n",
    "\n",
    "print(\"Classification report Random Forests ambiance with expectations: \\n\", class_rep_rf_ambiance_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm_rf_ambiance_exp = confusion_matrix(y_test_ambiance_exp, rf_ambiance_exp_pred)\n",
    "\n",
    "class_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_ambiance_exp, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Random Forests Ambiance Expectations')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
